---
title: "Multiple Linear Regression Analysis of Mobile Games User Intentions (1)"
author: "Andry S."
date: '2022-06-25'
output: 
  html_document: 
    toc: yes
---

# 1.1 Introduction

> This analysis is an analysis that uses multiple linear regression. This analysis will be divided into two parts. The first part, which is this section, is carried out data input, view, validity, and reliability tests.

# 1.2 Analysis Object

> Mobile games are video games that have evolved along with technological advances on smartphones as the main device for playing them. This sophistication makes mobile games not only as an entertainment medium, but also presents an element of competition, so that it can be played offline or online as well as multiplayer with various players around the world. The success of mobile games can be seen from the metrics of downloads generated and how often users play mobile games. Therefore, user intention can be a measure to achieve good downloads and usage.

# 1.3 Variable

> To achieve optimal analysis, it is necessary to use other variables such as Interest, Perception of Usability, and Perception of Ease as independent variables that affect the dependent variable, namely User Intentions. The use of these variables is based on the Technology Acceptance Model (TAM) theory by [Davis, Bagozzi, and Warshaw (1989).](https://scholar.google.com/citations?view_op=view_citation&hl=id&user=rKH2D8MAAAAJ&citation_for_view=rKH2D8MAAAAJ:u-x6o8ySG0sC) Therefore, in this analysis the variables used can be proxied as follows: Interest (X~1~) = I, Perception of Usability (X~2~) = PU, Perception of Ease (X~3~) = PE, and User Intentions (Y) = UI.

# 1.4 Data Retrieval

> The population used is mobile game users in Indonesia with an Infinite Population state. Therefore, a sample was taken using the Purposive Sampling technique as a representative of the population with the formula: n = 5 to 10 x observation variable (indicator), so that it is obtained n = 8 x 14 indicators = 112 respondent. The next step is to conduct a survey with a questionnaire with closed questions that are limited by a measurement scale with a Likert scale, namely from 1 = Strongly Disagree (SD), 2 = Disagree (D), 3 = Just Agree (JA), 4 = Agree (A), to 5 = Strongly Agree (SA).

# 1.5 Data Analysis

## 1.5.1 Data Input, View, and Summary

```{r}
# Data Input -> Likert
my_data1 <- read.csv("Dataset_UI_1.csv")

# Data Input -> Total Likert
my_data2 <- read.csv("Dataset_UI_2.csv")

# Data View -> Dataset_UI_1
my_data1

nrow(my_data1)
ncol(my_data1)
colnames(my_data1)
str(my_data1)

summary(my_data1)

# Data View -> Dataset_UI_2
my_data2

nrow(my_data2)
ncol(my_data2)
colnames(my_data2)
str(my_data2)

summary(my_data2)
```

## 1.5.2 Class Interval

```{r}
# Likert Class Interval Value
num_class = 5 # Likert 1-5
max_val <- max(my_data1)
min_val <- min(my_data1)

val_interval = (max_val - min_val)/num_class
val_interval
```

> Based on the calculations, the class interval is 0.8. Therefore, ranges and categories can be made, namely: 1.00-1.80 = DS, 1.81-2.60 = D, 2.61-3.40 = JA, 3.41-4.20 = A, dan 4.21-5.00 = SA.

## 1.5.3 Category Variables to Respondents

```{r}
# Number of indicators for each variable = 4

# Variable category -> Interest (I)
num_indicators = 4
vect_I <- my_data2[,"I"]
CategoryI <- mean(vect_I)/num_indicators
CategoryI

# Variable category -> Perception of Usability (PU)
vect_PU <- my_data2[,"PU"]
CategoryPU <- mean(vect_PU)/num_indicators
CategoryPU

# Variable category -> Perception of Ease (PE)
vect_PE <- my_data2[,"PE"]
CategoryPE <- mean(vect_PE)/num_indicators
CategoryPE

# Variable category -> User Intentions(UI)
vect_UI <- my_data2[,"UI"]
CategoryUI <- mean(vect_UI)/num_indicators
CategoryUI
```

> In the Interest variable (I) obtained 4.29, so it is included in the "SA" category. Variable Perception of Usability (PU) obtained 4.20, so it is included in the "A" category. The Perception of Ease (PE) variable was obtained 4.32, so it was included in the "SA" category. User Intentions (UI) variable obtained 4.05, so it is included in the "A" category.

## 1.5.4 Data Properties of Each Variable

```{r}
# Take each column of variables, then do a comparison between the "mean" value and the "standard deviation"

# Check column from "Dataset_UI_2.csv"
head(my_data2)
```

> After looking at the data column. Enter each column head that represents each variable and then create a vector.

```{r}


# Vector for Variable -> Interest
vec_dtI <- my_data2[, "I"]

# Comparison of the "mean" with "std.dev" (I)
statistics_I <- function(dt_I = vec_dtI){
  Mean <- mean(dt_I)
  Std.dev <- sd(dt_I)
  c(Mean = Mean, Std.dev = Std.dev)
}
statistics_I()

# Vector for Variable -> Perception of Usability
vec_dtPU <- my_data2[, "PU"]

# Comparison of the "mean" with "std.dev" (PU)
statistics_PU <- function(dt_PU = vec_dtPU){
  Mean <- mean(dt_PU)
  Std.dev <- sd(dt_PU)
  c(Mean = Mean, Std.dev = Std.dev)
}
statistics_PU()

# Vector for Variable -> Perception of Ease
vec_dtPE <- my_data2[, "PE"]

# Comparison of the "mean" with "std.dev" (PE)
statistics_PE <- function(dt_PE = vec_dtPE){
  Mean <- mean(dt_PE)
  Std.dev <- sd(dt_PE)
  c(Mean = Mean, Std.dev = Std.dev)
}
statistics_PE()

# Vector for Variable -> User Intentions
vec_dtUI <- my_data2[, "UI"]

# Comparison of the "mean" with "std.dev" (UI)
statistics_UI <- function(dt_UI = vec_dtUI){
  Mean <- mean(dt_UI)
  Std.dev <- sd(dt_UI)
  c(Mean = Mean, Std.dev = Std.dev)
}
statistics_UI()
```

> Based on these data, the mean of the variable "I" = 17.18, the variable "PU" = 16.8, the variable "PE" = 17.3, and the variable "UI" = 16.21. All mean values of each variable are greater (\>) than the resulting standard deviation. Therefore, the data obtained are homogeneous based on the comparison of the mean with the standard deviation. This means that the data values obtained from one another do not have a significant difference.

## 1.5.5 Instrument Test

```{r}
# Used for validity test
head(my_data1)

# Used for reliability test
head(my_data2) 
```

### 1. Validity Test

> The validity and reliability tests will be easier by using packages and libraries from "dplyr and psych"

```{r}

# install.packages("psych")
# install.packages("dplyr")

library(psych)
library(dplyr)

valid_I <- select(my_data1, 1, 2, 3, 4)
valid_PU <- select(my_data1, 5, 6, 7, 8)
valid_PE <- select(my_data1, 9, 10, 11, 12)
valid_UI <- select(my_data1, 13, 14, 15, 16)

alpha(valid_I)
alpha(valid_PU)
alpha(valid_PE)
alpha(valid_UI)

```

> In the validity test, it can be seen in the Item statistics section -\> raw.r. All indicator items of each variable have a value greater than [(r table)](https://docs.google.com/file/d/0B61KSjKBWIfsTjBpQVJqMXRtUnM/edit?resourcekey=0-2g4nzqZbpXryGHKY2jVdtA) with a significance level of 2-tailed (two-way) degree of freedom of 0.05 (5%) which is worth df = N-2 = 112-2 = 110, which is 0.186. This means that it can be concluded that all indicator items are **valid**.

### 2. Reliability Test

```{r}
reli <- (select(my_data2, 1, 2, 3, 4))
alpha(reli)
```

> In the reliability test, it can be seen in the Reliability section if an item is dropped: -\> raw_alpha. All variables have a value greater than Cronbach's Alpha which is worth 0.7 with a degree of freedom 0.05 (5%) [(based on nunnally's recommendations on the level of reliability in Early stage of research)](https://en.wikipedia.org/wiki/Cronbach%27s_alpha). This means that it can be concluded that all variables are **reliable**.

# 1.6 Info

> The whole code I write is purely based on logic and things I remember in R. There is probably better code writing out there. Here is the R information I used.

```{r}
sessionInfo()
```
